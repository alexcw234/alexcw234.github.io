---
layout: essay
type: essay
title: Config Management
date: 2017-01-31
labels:
  - ethics
  - automatic cars

---
## An Article for Thought
What does ethics mean in software engineering? Well my immediate response to that question is "you see this thing that could hurt people, don't do the thing".
But, in thinking about that question, I read [this article](https://www.technologyreview.com/s/542626/why-self-driving-cars-must-be-programmed-to-kill/) on self-driving cars titled "Why Self-Driving Cars Must Be Programmed to Kill".

The article talks about how the designers behind self-driving cars must deal with the ethical dilemma of choosing between killing a pedestrian(s) or the car's occupant(s). It provides the argument (correctly, in my opinion), that the car should be programmed to minimize the death toll. However, it also states findings that people who hold that view generally don't picture themselves as a passenger of the vehicle.

I think that the article definitely provided some interesting things to think about simply by bringing up the point that there will be situations in that it would be impossible to avoid a death-causing accident.
This is why ethics can't be simplified to simply "this thing could hurt people, so don't do the thing". That is, except when it can.

If I wasn't skeptical of self-driving cars already (which I am), I would have been made so from this article. After all, aside from the ethical dilemma, in presenting its findings it seems like the entire concept would fail to be accepted by the public. 
